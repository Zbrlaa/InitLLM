{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34a3e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.49.0\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch pandas scikit-learn matplotlib\n",
    "%pip install accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f0b995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modèle : mistralai/Mistral-7B-Instruct-v0.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e004886da04ea697dae2e99620c9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b18e4a4ffff4533a0d1204b4f71311f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cb45c5dd2b48e5acfafe6ef11c7ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af38b885099460d8710df4d07bf37c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df987484379e428ba4e0224e7660f2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2baaa59abe4c4e7284ae9031bd9a6d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd1b2ff95ea4b8b9ebaf8c1f89aa2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96389aeda2a3412db3f6cd15bda9c108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c176ae4e184620a3ae235a0f9f7c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecbb4e39a164e29afc64f1c5251f12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56938c9f6548446283b8b12923340f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85f096cd9de49b4ac9c80d6536e9b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Mistral-7B-Instruct chargé en 4-bit.\n"
     ]
    }
   ],
   "source": [
    "#Importations et configuration pour Mistral\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline, set_seed, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# --- Configuration du modèle Mistral 7B Instruct ---\n",
    "MODELE_NOM = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "print(f\"Chargement du modèle : {MODELE_NOM}...\")\n",
    "\n",
    "# Chargement du Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODELE_NOM)\n",
    "\n",
    "# Chargement du Modèle avec optimisation 4-bit (pour économiser la VRAM du GPU)\n",
    "# Necessite les librairies accelerate et bitsandbytes\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\tMODELE_NOM,\n",
    "\tload_in_4bit=True,\n",
    "\tdtype=torch.float16, # Utiliser float16 pour optimiser l'utilisation du GPU\n",
    "\tdevice_map=\"auto\" # Laisse Hugging Face décider où placer les couches (généralement sur le GPU)\n",
    ")\n",
    "\n",
    "# Création du Pipeline de génération\n",
    "generator = pipeline(\n",
    "\t'text-generation', \n",
    "\tmodel=model, \n",
    "\ttokenizer=tokenizer,\n",
    "\tmax_new_tokens=50, # Limiter la longueur des réponses pour la concision\n",
    "\t# device=model.device\n",
    ")\n",
    "\n",
    "set_seed(42) # Pour rendre les résultats reproductibles\n",
    "print(\"Modèle Mistral-7B-Instruct chargé en 4-bit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4793d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset créé avec 10 questions.\n",
      "   id                                           question  \\\n",
      "0   1  Quel est le nom complet du directeur de Poudla...   \n",
      "1   2  Quel objet est utilisé pour voyager dans le te...   \n",
      "2   3  Combien y a-t-il de Horcruxes créés par Lord V...   \n",
      "3   4  Quel sortilège est le sort de désarmement préf...   \n",
      "4   5         Quel est le nom du chat de Rubeus Hagrid ?   \n",
      "5   6  Quel est le nom de l'elfe de maison qui servai...   \n",
      "6   7  Dans quelle banque, dirigée par des gobelins, ...   \n",
      "7   8  Qui est le professeur de Potions qui prend la ...   \n",
      "8   9   Quelle est la forme du Patronus d'Harry Potter ?   \n",
      "9  10  Quelle créature, animal de compagnie d'Hagrid,...   \n",
      "\n",
      "                         reponse_reference  \n",
      "0  Albus Percival Wulfric Brian Dumbledore  \n",
      "1                      Retourneur de Temps  \n",
      "2                                     Sept  \n",
      "3                             Expelliarmus  \n",
      "4                              Miss Teigne  \n",
      "5                                    Dobby  \n",
      "6                                Gringotts  \n",
      "7                            Severus Rogue  \n",
      "8                                     Cerf  \n",
      "9                                 Buckbeak  \n"
     ]
    }
   ],
   "source": [
    "#Création du dataset Harry Potter\n",
    "hp_questions_data = [\n",
    "\t{\n",
    "\t\t\"id\": 1,\n",
    "\t\t\"question\": \"Quel est le nom complet du directeur de Poudlard au début de la série ?\",\n",
    "\t\t\"reponse_reference\": \"Albus Percival Wulfric Brian Dumbledore\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 2,\n",
    "\t\t\"question\": \"Quel objet est utilisé pour voyager dans le temps dans le troisième livre ?\",\n",
    "\t\t\"reponse_reference\": \"Retourneur de Temps\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 3,\n",
    "\t\t\"question\": \"Combien y a-t-il de Horcruxes créés par Lord Voldemort ?\",\n",
    "\t\t\"reponse_reference\": \"Sept\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 4,\n",
    "\t\t\"question\": \"Quel sortilège est le sort de désarmement préféré d'Harry Potter ?\",\n",
    "\t\t\"reponse_reference\": \"Expelliarmus\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 5,\n",
    "\t\t\"question\": \"Quel est le nom du chat de Rubeus Hagrid ?\", # Question piège (c'est Rusard) mais l'important est la référence\n",
    "\t\t\"reponse_reference\": \"Miss Teigne\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 6,\n",
    "\t\t\"question\": \"Quel est le nom de l'elfe de maison qui servait la famille Malefoy et a été libéré par Harry ?\",\n",
    "\t\t\"reponse_reference\": \"Dobby\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 7,\n",
    "\t\t\"question\": \"Dans quelle banque, dirigée par des gobelins, les sorciers gardent-ils leur argent ?\",\n",
    "\t\t\"reponse_reference\": \"Gringotts\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 8,\n",
    "\t\t\"question\": \"Qui est le professeur de Potions qui prend la défense contre les forces du mal dans le sixième livre ?\",\n",
    "\t\t\"reponse_reference\": \"Severus Rogue\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 9,\n",
    "\t\t\"question\": \"Quelle est la forme du Patronus d'Harry Potter ?\",\n",
    "\t\t\"reponse_reference\": \"Cerf\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": 10,\n",
    "\t\t\"question\": \"Quelle créature, animal de compagnie d'Hagrid, est condamnée à mort mais sauvée par Harry et Hermione ?\",\n",
    "\t\t\"reponse_reference\": \"Buckbeak\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "df_hp = pd.DataFrame(hp_questions_data)\n",
    "print(f\"Dataset créé avec {len(df_hp)} questions.\")\n",
    "print(df_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e7f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonctions pour construire les Prompts\n",
    "\n",
    "SYSTEM_INSTRUCTION = \"Tu es un assistant expert sur l'univers d'Harry Potter. Réponds de manière factuelle et concise.\"\n",
    "\n",
    "def formater_prompt_mistral(prompt_utilisateur: str) -> str:\n",
    "\t\"\"\"Applique le format d'instruction strict de Mistral.\"\"\"\n",
    "\t# Le format est : <s>[INST] Instruction [/INST]\n",
    "\treturn f\"<s>[INST] {prompt_utilisateur} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c0c2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_prompt_zero_shot(question_actuelle: str) -> str:\n",
    "\t\"\"\"Crée un prompt Zero-Shot.\"\"\"\n",
    "\t\n",
    "\tprompt_utilisateur = (\n",
    "\t\tf\"{SYSTEM_INSTRUCTION}\\n\\n\"\n",
    "\t\tf\"Question: {question_actuelle}\\n\"\n",
    "\t\tf\"Réponse:\"\n",
    "\t)\n",
    "\t\n",
    "\treturn formater_prompt_mistral(prompt_utilisateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cf5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_prompt_one_shot(question_actuelle: str, df_data: pd.DataFrame) -> str:\n",
    "\t\"\"\"Crée un prompt One-Shot en utilisant la première entrée du DataFrame comme exemple.\"\"\"\n",
    "\t\n",
    "\t# Récupérer le premier exemple\n",
    "\texemple = df_data.iloc[0]\n",
    "\t\n",
    "\texemples_prompt = (\n",
    "\t\tf\"Question: {exemple['question']}\\n\"\n",
    "\t\tf\"Réponse: {exemple['reponse_reference']}\\n\\n\"\n",
    "\t)\n",
    "\t\n",
    "\tprompt_utilisateur = (\n",
    "\t\tf\"{SYSTEM_INSTRUCTION}\\n\\n\"\n",
    "\t\tf\"--- Exemple de Format ---\\n\"\n",
    "\t\tf\"{exemples_prompt}\"\n",
    "\t\tf\"--- Fin de l'Exemple ---\\n\\n\"\n",
    "\t\tf\"Question: {question_actuelle}\\n\"\n",
    "\t\tf\"Réponse:\"\n",
    "\t)\n",
    "\t\n",
    "\treturn formater_prompt_mistral(prompt_utilisateur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a2c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_prompt_few_shot(question_actuelle: str, df_data: pd.DataFrame, nb_exemples: int = 3) -> str:\n",
    "\t\"\"\"Crée un prompt Few-Shot en utilisant les N premières entrées du DataFrame comme exemples.\"\"\"\n",
    "\t\n",
    "\t# Récupérer les N premiers exemples (s'assurer qu'on ne dépasse pas la taille du DF)\n",
    "\texemples = df_data.head(nb_exemples)\n",
    "\t\n",
    "\texemples_prompt = \"\"\n",
    "\tfor index, row in exemples.iterrows():\n",
    "\t\t# Utiliser le format simple Q:X, R:Y\n",
    "\t\texemples_prompt += (\n",
    "\t\t\tf\"Question: {row['question']}\\n\"\n",
    "\t\t\tf\"Réponse: {row['reponse_reference']}\\n\\n\"\n",
    "\t\t)\n",
    "\t\t\n",
    "\tprompt_utilisateur = (\n",
    "\t\tf\"{SYSTEM_INSTRUCTION}\\n\\n\"\n",
    "\t\tf\"--- Exemples de Format ({nb_exemples} au total) ---\\n\"\n",
    "\t\tf\"{exemples_prompt}\"\n",
    "\t\tf\"--- Fin des Exemples ---\\n\\n\"\n",
    "\t\tf\"Question: {question_actuelle}\\n\"\n",
    "\t\tf\"Réponse:\"\n",
    "\t)\n",
    "\t\n",
    "\treturn formater_prompt_mistral(prompt_utilisateur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
